import express from "express";
import fetch from "node-fetch";

const app = express();
app.use(express.json());

// ç’°å¢ƒå¤‰æ•°
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GEMINI_MODEL = process.env.GEMINI_MODEL || "models/gemini-2.5-flash-lite";
const TAVILY_API_KEY = process.env.TAVILY_API_KEY;
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;

// ã‚µãƒ¼ãƒ“ã‚¹ç¨¼åƒç¢ºèª
app.get("/", (_, res) =>
  res.send(`âœ… Gemini + OpenRouter Proxy running (default model: ${GEMINI_MODEL})`)
);

// OpenAIäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
app.post("/v1/chat/completions", async (req, res) => {
  try {
    const { model, messages } = req.body;
    const selectedModel = model || GEMINI_MODEL;

    if (!messages || !Array.isArray(messages) || messages.length === 0) {
      return res.status(400).json({ error: "No messages found" });
    }

    // æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    const lastUserMessage = messages.filter(m => m.role === "user").slice(-1)[0]?.content;
    if (!lastUserMessage) return res.status(400).json({ error: "No user text found" });

    // Tavilyæ¤œç´¢ï¼ˆä»»æ„ï¼‰
    let context = "ï¼ˆæ¤œç´¢çµæœãªã—ï¼‰";
    if (TAVILY_API_KEY) {
      try {
        const tavilyRes = await fetch("https://api.tavily.com/search", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: `Bearer ${TAVILY_API_KEY}`,
          },
          body: JSON.stringify({ query: lastUserMessage, max_results: 3 }),
        });
        const tavilyData = await safeJson(tavilyRes);
        context =
          tavilyData.results?.map(r => `- ${r.title}\n${r.content}`).join("\n\n") ||
          context;
      } catch (err) {
        console.error("Tavily search error:", err);
      }
    }

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ½å‡º
    const systemPrompt = messages.find(m => m.role === "system")?.content || "";

    // å±¥æ­´ç”Ÿæˆ
    const chatHistory = messages.filter(m => m.role !== "system")
      .map(m => `${m.role}: ${m.content}`).join("\n\n");

    const promptWithContext = `
ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:
${systemPrompt}

æ¤œç´¢çµæœ:
${context}

ä¼šè©±å±¥æ­´:
${chatHistory}
`;

    let answer = "ï¼ˆå›ç­”ãªã—ï¼‰";

    // ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æŒ¯ã‚Šåˆ†ã‘
    if (selectedModel.startsWith("openrouter:")) {
      // OpenRouterã®å ´åˆ
      const modelName = selectedModel.replace(/^openrouter:/, "");
      answer = await callOpenRouter(modelName, messages);
    } else {
      // Geminiã®å ´åˆ
      answer = await callGemini(selectedModel, promptWithContext);
    }

    // OpenAIäº’æ›ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¿”å´
    res.json({
      id: `chatcmpl-${Date.now()}`,
      object: "chat.completion",
      created: Math.floor(Date.now() / 1000),
      model: selectedModel,
      choices: [
        {
          index: 0,
          message: { role: "assistant", content: answer },
          finish_reason: "stop",
        },
      ],
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: err.message });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () =>
  console.log(`ğŸŒ Server running on port ${PORT}`)
);

// -----------------------------
// Gemini APIå‘¼ã³å‡ºã—
// -----------------------------
async function callGemini(model, promptWithContext) {
  try {
    const res = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/${model}:generateContent?key=${GEMINI_API_KEY}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ role: "user", parts: [{ text: promptWithContext }] }],
          safetySettings: [
            { category: "HARM_CATEGORY_HARASSMENT", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_HATE_SPEECH", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold: "BLOCK_NONE" },
            { category: "HARM_CATEGORY_DANGEROUS_CONTENT", threshold: "BLOCK_NONE" }
          ]
        }),
      }
    );
    const data = await safeJson(res);
    return data?.candidates?.[0]?.content?.parts?.[0]?.text || "ï¼ˆGeminiã‹ã‚‰å›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰";
  } catch (err) {
    console.error("Gemini API error:", err);
    return "ï¼ˆGeminiå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰";
  }
}

// -----------------------------
// OpenRouter APIå‘¼ã³å‡ºã—
// -----------------------------
async function callOpenRouter(modelName, messages) {
  try {
    const res = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENROUTER_API_KEY}`
      },
      body: JSON.stringify({
        model: modelName,
        messages: messages
      })
    });
    const data = await safeJson(res);
    return data?.choices?.[0]?.message?.content || "ï¼ˆOpenRouterã‹ã‚‰å›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰";
  } catch (err) {
    console.error("OpenRouter API error:", err);
    return "ï¼ˆOpenRouterå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼‰";
  }
}

// -----------------------------
// å®‰å…¨ãªJSONè§£æ
// -----------------------------
async function safeJson(res) {
  const text = await res.text();
  try { return JSON.parse(text); }
  catch { 
    console.error("âš ï¸ Invalid JSON:", text.slice(0, 500));
    return {};
  }
}
