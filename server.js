import express from "express";
import fetch from "node-fetch";

const app = express();
app.use(express.json());

// ğŸ”‘ ç’°å¢ƒå¤‰æ•°
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const TAVILY_API_KEY = process.env.TAVILY_API_KEY;
const DEFAULT_MODEL = process.env.GEMINI_MODEL || "models/gemini-2.5-flash-lite";

// ğŸ” å‹•ä½œç¢ºèª
app.get("/", (_, res) =>
  res.send(`âœ… Gemini Search Proxy is running!`)
);

// ğŸ’¬ JSONå®‰å…¨ãƒ‘ãƒ¼ã‚¹
async function safeJson(res) {
  const text = await res.text();
  try {
    return JSON.parse(text);
  } catch (err) {
    console.error("âš ï¸ JSON parse failed:", text.slice(0, 500));
    return {};
  }
}

// ğŸ’¬ ãƒ¡ã‚¤ãƒ³å‡¦ç†
app.post("/ask", async (req, res) => {
  // OpenAIå½¢å¼ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰è³ªå•æ–‡ã‚’æŠ½å‡º
  const model = req.body.model || DEFAULT_MODEL;
  const messages = req.body.messages;
  if (!messages || !Array.isArray(messages) || messages.length === 0)
    return res.status(400).json({ error: "Missing messages in body" });

  // æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
  const userMsg = messages.reverse().find(m => m.role === "user");
  const query = userMsg?.content?.[0]?.text;
  if (!query) return res.status(400).json({ error: "No user text found" });

  try {
    // 1ï¸âƒ£ Tavily ã§æ¤œç´¢
    const tavilyRes = await fetch("https://api.tavily.com/search", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${TAVILY_API_KEY}`,
      },
      body: JSON.stringify({ query, max_results: 3 }),
    });

    const tavily = await safeJson(tavilyRes);
    const context =
      tavily.results?.map(r => `- ${r.title}\n${r.content}`).join("\n\n") ||
      "ï¼ˆæ¤œç´¢çµæœãªã—ï¼‰";

    // 2ï¸âƒ£ Gemini ã«è³ªå•
    const prompt = `
æ¬¡ã®æ¤œç´¢çµæœã‚’ã‚‚ã¨ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
è³ªå•: ${query}

æ¤œç´¢çµæœ:
${context}
    `;

    // ğŸ”¹ v1/v1beta è‡ªå‹•åˆ‡æ›¿
    const geminiURL = model.startsWith("gemini-2")
      ? `https://generativelanguage.googleapis.com/v1beta/${model}:generateContent?key=${GEMINI_API_KEY}`
      : `https://generativelanguage.googleapis.com/v1/${model}:generateContent?key=${GEMINI_API_KEY}`;

    const geminiRes = await fetch(geminiURL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        contents: [{ role: "user", parts: [{ text: prompt }] }],
      }),
    });

    const rawText = await geminiRes.text();
    console.log("ğŸ’¡ Gemini raw text response:", rawText);

    const gemini = (() => {
      try {
        return JSON.parse(rawText);
      } catch {
        return {};
      }
    })();

    const answer =
      gemini?.candidates?.[0]?.content?.parts?.[0]?.text ||
      "ï¼ˆGeminiã‹ã‚‰å›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼‰";

    // ğŸ”¹ OpenAI Chat API äº’æ›å½¢å¼ã§è¿”ã™
    res.json({
      id: "chatcmpl-agnai-" + Date.now(),
      object: "chat.completion",
      created: Math.floor(Date.now() / 1000),
      model: model,
      choices: [
        {
          index: 0,
          message: {
            role: "assistant",
            content: [{ text: answer }],
          },
          finish_reason: "stop",
        },
      ],
    });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: err.message });
  }
});

// ğŸ”¹ Render ç”¨ãƒãƒ¼ãƒˆ
const PORT = process.env.PORT || 3000;
app.listen(PORT, () =>
  console.log(`ğŸŒ Server running on port ${PORT}`)
);
